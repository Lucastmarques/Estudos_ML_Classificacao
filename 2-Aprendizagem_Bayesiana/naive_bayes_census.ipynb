{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "base = pd.read_csv('census.csv')\n",
    "\n",
    "previsores = base.iloc[:, 0:14].values\n",
    "classe = base.iloc[:, 14].values\n",
    "                \n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "labelencoder_previsores = LabelEncoder()\n",
    "### LabelEncoder().fit_transform(np.array) transforma variáveis categóricas em numéricas\n",
    "previsores[:, 1] = labelencoder_previsores.fit_transform(previsores[:, 1])\n",
    "previsores[:, 3] = labelencoder_previsores.fit_transform(previsores[:, 3])\n",
    "previsores[:, 5] = labelencoder_previsores.fit_transform(previsores[:, 5])\n",
    "previsores[:, 6] = labelencoder_previsores.fit_transform(previsores[:, 6])\n",
    "previsores[:, 7] = labelencoder_previsores.fit_transform(previsores[:, 7])\n",
    "previsores[:, 8] = labelencoder_previsores.fit_transform(previsores[:, 8])\n",
    "previsores[:, 9] = labelencoder_previsores.fit_transform(previsores[:, 9])\n",
    "previsores[:, 13] = labelencoder_previsores.fit_transform(previsores[:, 13])\n",
    "\n",
    "column_tranformer = ColumnTransformer([('one_hot_encoder', OneHotEncoder(), [1, 3, 5, 6, 7, 8, 9, 13])],remainder='passthrough')\n",
    "previsores = column_tranformer.fit_transform(previsores).toarray()\n",
    "\n",
    "labelencoder_classe = LabelEncoder()\n",
    "classe = labelencoder_classe.fit_transform(classe)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "previsores = scaler.fit_transform(previsores)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "previsores_treinamento, previsores_teste, classe_treinamento, classe_teste = train_test_split(previsores, classe, test_size=0.15, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Precisão:  0.4767656090071648\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[1172, 2521],\n       [  35, 1157]], dtype=int64)"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "classificador = GaussianNB()\n",
    "### Treinando a máquina com os dados de treinamento\n",
    "classificador.fit(previsores_treinamento, classe_treinamento)\n",
    "\n",
    "### Fazendo as previsões e armazenando em previsoes\n",
    "previsoes = classificador.predict(previsores_teste)\n",
    "\n",
    "### Comparando as previsões com o resultado real\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "precisao = accuracy_score(classe_teste, previsoes)\n",
    "print(\"Precisão: \", precisao)\n",
    "matriz = confusion_matrix(classe_teste, previsoes)\n",
    "matriz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rodando o código sem a padronização dos atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Precisão:  0.7950870010235415\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[3515,  178],\n       [ 823,  369]], dtype=int64)"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "base = pd.read_csv('census.csv')\n",
    "\n",
    "previsores = base.iloc[:, 0:14].values\n",
    "classe = base.iloc[:, 14].values\n",
    "                \n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "column_tranformer = ColumnTransformer([('one_hot_encoder', OneHotEncoder(), [1, 3, 5, 6, 7, 8, 9, 13])],remainder='passthrough')\n",
    "previsores = column_tranformer.fit_transform(previsores).toarray()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "previsores_treinamento, previsores_teste, classe_treinamento, classe_teste = train_test_split(previsores, classe, test_size=0.15, random_state=0)\n",
    "\n",
    "### Treinando a máquina com os dados de treinamento\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classificador = GaussianNB()\n",
    "classificador.fit(previsores_treinamento, classe_treinamento)\n",
    "\n",
    "### Fazendo as previsões e armazenando em previsoes\n",
    "previsoes = classificador.predict(previsores_teste)\n",
    "\n",
    "### Comparando as previsões com o resultado real\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "precisao = accuracy_score(classe_teste, previsoes)\n",
    "print(\"Precisão: \", precisao)\n",
    "matriz = confusion_matrix(classe_teste, previsoes)\n",
    "matriz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "\n",
    "PERCEBA QUE NEM SEMPRE O QUE PARECE SER ÓBVIO É DE FATO MELHOR!\n",
    "\n",
    "NESSE CASO, A PADRONIZAÇÃO DOS DADOS GERAVA ERROS NO ALGORATIMO, DIMINUINDO A SUA PRECISÃO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}