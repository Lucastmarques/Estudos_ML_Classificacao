{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neurais Keras Census\n",
    "\n",
    "## Utilizando Escalonamento + LabelEncoder + OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "base = pd.read_csv('census.csv')\n",
    "previsores = base.iloc[:, 0:14].values\n",
    "classe = base.iloc[:, 14].values\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "previsores[:, 1] = labelencoder.fit_transform(previsores[:, 1])\n",
    "previsores[:, 3] = labelencoder.fit_transform(previsores[:, 3])\n",
    "previsores[:, 5] = labelencoder.fit_transform(previsores[:, 5])\n",
    "previsores[:, 6] = labelencoder.fit_transform(previsores[:, 6])\n",
    "previsores[:, 7] = labelencoder.fit_transform(previsores[:, 7])\n",
    "previsores[:, 8] = labelencoder.fit_transform(previsores[:, 8])\n",
    "previsores[:, 9] = labelencoder.fit_transform(previsores[:, 9])\n",
    "previsores[:, 13] = labelencoder.fit_transform(previsores[:, 13])\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "onehotencorder = ColumnTransformer(transformers=[(\"OneHot\", OneHotEncoder(), [1,3,5,6,7,8,9,13])], remainder='passthrough')\n",
    "previsores = onehotencorder.fit_transform(previsores).toarray()\n",
    "\n",
    "labelencoder_classe = LabelEncoder()\n",
    "classe = labelencoder_classe.fit_transform(classe)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "previsores = scaler.fit_transform(previsores)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "previsores_treinamento, previsores_teste, classe_treinamento, classe_teste = train_test_split(previsores, classe, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "classificador = Sequential()\n",
    "### Criando camadas escondidas\n",
    "classificador.add(Dense(units=55, activation='relu', input_dim=108))\n",
    "classificador.add(Dense(units=55, activation='relu'))\n",
    "### Criando camada de sa√≠da\n",
    "classificador.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "classificador.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/100\n24420/24420 [==============================] - 2s 66us/step - loss: 0.3439 - accuracy: 0.8386\nEpoch 2/100\n24420/24420 [==============================] - 1s 60us/step - loss: 0.3161 - accuracy: 0.8516\nEpoch 3/100\n24420/24420 [==============================] - 1s 61us/step - loss: 0.3073 - accuracy: 0.8579\nEpoch 4/100\n24420/24420 [==============================] - 2s 63us/step - loss: 0.3016 - accuracy: 0.8603\nEpoch 5/100\n24420/24420 [==============================] - 2s 62us/step - loss: 0.2975 - accuracy: 0.8610\nEpoch 6/100\n24420/24420 [==============================] - 2s 63us/step - loss: 0.2920 - accuracy: 0.8640\nEpoch 7/100\n24420/24420 [==============================] - 1s 60us/step - loss: 0.2876 - accuracy: 0.8674\nEpoch 8/100\n24420/24420 [==============================] - 1s 60us/step - loss: 0.2834 - accuracy: 0.8680\nEpoch 9/100\n24420/24420 [==============================] - 1s 61us/step - loss: 0.2798 - accuracy: 0.8702\nEpoch 10/100\n24420/24420 [==============================] - 1s 60us/step - loss: 0.2749 - accuracy: 0.8717\nEpoch 11/100\n24420/24420 [==============================] - 1s 60us/step - loss: 0.2712 - accuracy: 0.8737\nEpoch 12/100\n24420/24420 [==============================] - 1s 61us/step - loss: 0.2662 - accuracy: 0.8768\nEpoch 13/100\n24420/24420 [==============================] - 1s 61us/step - loss: 0.2624 - accuracy: 0.8769\nEpoch 14/100\n24420/24420 [==============================] - 2s 62us/step - loss: 0.2583 - accuracy: 0.8790\nEpoch 15/100\n24420/24420 [==============================] - 2s 63us/step - loss: 0.2551 - accuracy: 0.8792\nEpoch 16/100\n24420/24420 [==============================] - 2s 62us/step - loss: 0.2500 - accuracy: 0.8834\nEpoch 17/100\n24420/24420 [==============================] - 1s 61us/step - loss: 0.2477 - accuracy: 0.8848\nEpoch 18/100\n24420/24420 [==============================] - 2s 65us/step - loss: 0.2431 - accuracy: 0.8864\nEpoch 19/100\n24420/24420 [==============================] - 2s 65us/step - loss: 0.2401 - accuracy: 0.8877\nEpoch 20/100\n24420/24420 [==============================] - 2s 63us/step - loss: 0.2371 - accuracy: 0.8889\nEpoch 21/100\n24420/24420 [==============================] - 2s 63us/step - loss: 0.2350 - accuracy: 0.8897\nEpoch 22/100\n24420/24420 [==============================] - 2s 62us/step - loss: 0.2322 - accuracy: 0.8905\nEpoch 23/100\n24420/24420 [==============================] - 2s 63us/step - loss: 0.2284 - accuracy: 0.8911\nEpoch 24/100\n24420/24420 [==============================] - 2s 63us/step - loss: 0.2260 - accuracy: 0.8937\nEpoch 25/100\n24420/24420 [==============================] - 2s 65us/step - loss: 0.2233 - accuracy: 0.8946\nEpoch 26/100\n24420/24420 [==============================] - 2s 65us/step - loss: 0.2203 - accuracy: 0.8958\nEpoch 27/100\n24420/24420 [==============================] - 2s 63us/step - loss: 0.2188 - accuracy: 0.8983\nEpoch 28/100\n24420/24420 [==============================] - 2s 70us/step - loss: 0.2148 - accuracy: 0.8983\nEpoch 29/100\n24420/24420 [==============================] - 2s 74us/step - loss: 0.2125 - accuracy: 0.9007\nEpoch 30/100\n24420/24420 [==============================] - 2s 74us/step - loss: 0.2108 - accuracy: 0.9010\nEpoch 31/100\n24420/24420 [==============================] - 2s 73us/step - loss: 0.2089 - accuracy: 0.9033\nEpoch 32/100\n24420/24420 [==============================] - 2s 74us/step - loss: 0.2065 - accuracy: 0.9031\nEpoch 33/100\n24420/24420 [==============================] - 2s 71us/step - loss: 0.2048 - accuracy: 0.9044\nEpoch 34/100\n24420/24420 [==============================] - 2s 65us/step - loss: 0.2031 - accuracy: 0.9041\nEpoch 35/100\n24420/24420 [==============================] - 2s 66us/step - loss: 0.2021 - accuracy: 0.9059\nEpoch 36/100\n24420/24420 [==============================] - 2s 65us/step - loss: 0.1986 - accuracy: 0.9073\nEpoch 37/100\n24420/24420 [==============================] - 2s 65us/step - loss: 0.1962 - accuracy: 0.9086\nEpoch 38/100\n24420/24420 [==============================] - 2s 65us/step - loss: 0.1966 - accuracy: 0.9078\nEpoch 39/100\n24420/24420 [==============================] - 2s 63us/step - loss: 0.1951 - accuracy: 0.9098\nEpoch 40/100\n24420/24420 [==============================] - 2s 64us/step - loss: 0.1921 - accuracy: 0.9097\nEpoch 41/100\n24420/24420 [==============================] - 2s 63us/step - loss: 0.1927 - accuracy: 0.9092\nEpoch 42/100\n24420/24420 [==============================] - 2s 63us/step - loss: 0.1892 - accuracy: 0.9117\nEpoch 43/100\n24420/24420 [==============================] - 2s 66us/step - loss: 0.1890 - accuracy: 0.9108\nEpoch 44/100\n24420/24420 [==============================] - 2s 63us/step - loss: 0.1866 - accuracy: 0.9123\nEpoch 45/100\n24420/24420 [==============================] - 2s 63us/step - loss: 0.1869 - accuracy: 0.9141\nEpoch 46/100\n24420/24420 [==============================] - 2s 63us/step - loss: 0.1842 - accuracy: 0.9149\nEpoch 47/100\n24420/24420 [==============================] - 2s 63us/step - loss: 0.1851 - accuracy: 0.9131\nEpoch 48/100\n24420/24420 [==============================] - 2s 63us/step - loss: 0.1832 - accuracy: 0.9144\nEpoch 49/100\n24420/24420 [==============================] - 2s 64us/step - loss: 0.1815 - accuracy: 0.9156\nEpoch 50/100\n24420/24420 [==============================] - 2s 63us/step - loss: 0.1806 - accuracy: 0.9152\nEpoch 51/100\n24420/24420 [==============================] - 2s 64us/step - loss: 0.1789 - accuracy: 0.9180\nEpoch 52/100\n24420/24420 [==============================] - 2s 65us/step - loss: 0.1769 - accuracy: 0.9174\nEpoch 53/100\n24420/24420 [==============================] - 2s 64us/step - loss: 0.1764 - accuracy: 0.9189\nEpoch 54/100\n24420/24420 [==============================] - 2s 63us/step - loss: 0.1774 - accuracy: 0.9172\nEpoch 55/100\n24420/24420 [==============================] - 2s 63us/step - loss: 0.1729 - accuracy: 0.9195\nEpoch 56/100\n24420/24420 [==============================] - 2s 65us/step - loss: 0.1740 - accuracy: 0.9179\nEpoch 57/100\n24420/24420 [==============================] - 2s 66us/step - loss: 0.1727 - accuracy: 0.9188\nEpoch 58/100\n24420/24420 [==============================] - 2s 66us/step - loss: 0.1727 - accuracy: 0.9191\nEpoch 59/100\n24420/24420 [==============================] - 2s 67us/step - loss: 0.1708 - accuracy: 0.9203\nEpoch 60/100\n24420/24420 [==============================] - 2s 64us/step - loss: 0.1700 - accuracy: 0.9207\nEpoch 61/100\n24420/24420 [==============================] - 2s 62us/step - loss: 0.1680 - accuracy: 0.9222\nEpoch 62/100\n24420/24420 [==============================] - 2s 65us/step - loss: 0.1687 - accuracy: 0.9195\nEpoch 63/100\n24420/24420 [==============================] - 2s 65us/step - loss: 0.1673 - accuracy: 0.9211\nEpoch 64/100\n24420/24420 [==============================] - 2s 62us/step - loss: 0.1670 - accuracy: 0.9224\nEpoch 65/100\n24420/24420 [==============================] - 2s 63us/step - loss: 0.1652 - accuracy: 0.9230\nEpoch 66/100\n24420/24420 [==============================] - 2s 62us/step - loss: 0.1645 - accuracy: 0.9226\nEpoch 67/100\n24420/24420 [==============================] - 2s 62us/step - loss: 0.1633 - accuracy: 0.9247\nEpoch 68/100\n24420/24420 [==============================] - 2s 63us/step - loss: 0.1628 - accuracy: 0.9254\nEpoch 69/100\n24420/24420 [==============================] - 2s 62us/step - loss: 0.1630 - accuracy: 0.9250\nEpoch 70/100\n24420/24420 [==============================] - 2s 63us/step - loss: 0.1606 - accuracy: 0.9259\nEpoch 71/100\n24420/24420 [==============================] - 2s 62us/step - loss: 0.1606 - accuracy: 0.9238\nEpoch 72/100\n24420/24420 [==============================] - 2s 64us/step - loss: 0.1600 - accuracy: 0.9261\nEpoch 73/100\n24420/24420 [==============================] - 2s 65us/step - loss: 0.1589 - accuracy: 0.9253\nEpoch 74/100\n24420/24420 [==============================] - 2s 65us/step - loss: 0.1576 - accuracy: 0.9270\nEpoch 75/100\n24420/24420 [==============================] - 2s 62us/step - loss: 0.1579 - accuracy: 0.9258\nEpoch 76/100\n24420/24420 [==============================] - 2s 63us/step - loss: 0.1566 - accuracy: 0.9260\nEpoch 77/100\n24420/24420 [==============================] - 2s 64us/step - loss: 0.1567 - accuracy: 0.9275\nEpoch 78/100\n24420/24420 [==============================] - 2s 65us/step - loss: 0.1535 - accuracy: 0.9287\nEpoch 79/100\n24420/24420 [==============================] - 2s 66us/step - loss: 0.1549 - accuracy: 0.9288\nEpoch 80/100\n24420/24420 [==============================] - 2s 65us/step - loss: 0.1547 - accuracy: 0.9284\nEpoch 81/100\n24420/24420 [==============================] - 2s 67us/step - loss: 0.1548 - accuracy: 0.9278\nEpoch 82/100\n24420/24420 [==============================] - 2s 63us/step - loss: 0.1523 - accuracy: 0.9293\nEpoch 83/100\n24420/24420 [==============================] - 2s 64us/step - loss: 0.1529 - accuracy: 0.9291\nEpoch 84/100\n24420/24420 [==============================] - 2s 62us/step - loss: 0.1512 - accuracy: 0.9289\nEpoch 85/100\n24420/24420 [==============================] - 2s 65us/step - loss: 0.1516 - accuracy: 0.9292\nEpoch 86/100\n24420/24420 [==============================] - 2s 64us/step - loss: 0.1507 - accuracy: 0.9308\nEpoch 87/100\n24420/24420 [==============================] - 2s 69us/step - loss: 0.1487 - accuracy: 0.9331\nEpoch 88/100\n24420/24420 [==============================] - 2s 66us/step - loss: 0.1504 - accuracy: 0.9306\nEpoch 89/100\n24420/24420 [==============================] - 2s 64us/step - loss: 0.1490 - accuracy: 0.9303\nEpoch 90/100\n24420/24420 [==============================] - 2s 64us/step - loss: 0.1462 - accuracy: 0.9319\nEpoch 91/100\n24420/24420 [==============================] - 2s 64us/step - loss: 0.1488 - accuracy: 0.9305\nEpoch 92/100\n24420/24420 [==============================] - 2s 65us/step - loss: 0.1485 - accuracy: 0.9311\nEpoch 93/100\n24420/24420 [==============================] - 2s 64us/step - loss: 0.1475 - accuracy: 0.9314\nEpoch 94/100\n24420/24420 [==============================] - 2s 67us/step - loss: 0.1474 - accuracy: 0.9312\nEpoch 95/100\n24420/24420 [==============================] - 2s 64us/step - loss: 0.1440 - accuracy: 0.9343\nEpoch 96/100\n24420/24420 [==============================] - 2s 64us/step - loss: 0.1467 - accuracy: 0.9323\nEpoch 97/100\n24420/24420 [==============================] - 2s 62us/step - loss: 0.1456 - accuracy: 0.9319\nEpoch 98/100\n24420/24420 [==============================] - 2s 63us/step - loss: 0.1440 - accuracy: 0.9335\nEpoch 99/100\n24420/24420 [==============================] - 2s 63us/step - loss: 0.1454 - accuracy: 0.9337\nEpoch 100/100\n24420/24420 [==============================] - 2s 63us/step - loss: 0.1438 - accuracy: 0.9325\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<keras.callbacks.callbacks.History at 0x18c91077608>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "### Batch_size faz com que atualize os pesos a cada 10 dados e treina por 100 √©pocas\n",
    "classificador.fit(previsores_treinamento, classe_treinamento, batch_size=10, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes = classificador.predict(previsores_teste)\n",
    "### Fazendo com que o retorno seja verdadeiro ou falso, baseado num valor m√©dio de 0,5\n",
    "previsoes = (previsoes > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Precis√£o: 0.8243459034516644\n[[5482  677]\n [ 753 1229]]\n"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "precisao = accuracy_score(classe_teste, previsoes)\n",
    "matriz = confusion_matrix(classe_teste, previsoes)\n",
    "print('Precis√£o: ', precisao)\n",
    "print(matriz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizando Escalonamento + LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "base = pd.read_csv('census.csv')\n",
    "previsores = base.iloc[:, 0:14].values\n",
    "classe = base.iloc[:, 14].values\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "previsores[:, 1] = labelencoder.fit_transform(previsores[:, 1])\n",
    "previsores[:, 3] = labelencoder.fit_transform(previsores[:, 3])\n",
    "previsores[:, 5] = labelencoder.fit_transform(previsores[:, 5])\n",
    "previsores[:, 6] = labelencoder.fit_transform(previsores[:, 6])\n",
    "previsores[:, 7] = labelencoder.fit_transform(previsores[:, 7])\n",
    "previsores[:, 8] = labelencoder.fit_transform(previsores[:, 8])\n",
    "previsores[:, 9] = labelencoder.fit_transform(previsores[:, 9])\n",
    "previsores[:, 13] = labelencoder.fit_transform(previsores[:, 13])\n",
    "\n",
    "labelencoder_classe = LabelEncoder()\n",
    "classe = labelencoder_classe.fit_transform(classe)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "previsores = scaler.fit_transform(previsores)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "previsores_treinamento, previsores_teste, classe_treinamento, classe_teste = train_test_split(previsores, classe, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "classificador = Sequential()\n",
    "### Criando camadas escondidas\n",
    "classificador.add(Dense(units=55, activation='relu', input_dim=14))\n",
    "classificador.add(Dense(units=55, activation='relu'))\n",
    "### Criando camada de sa√≠da\n",
    "classificador.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "classificador.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/100\n24420/24420 [==============================] - 2s 64us/step - loss: 0.3508 - accuracy: 0.8370\nEpoch 2/100\n24420/24420 [==============================] - 2s 62us/step - loss: 0.3263 - accuracy: 0.8482\nEpoch 3/100\n24420/24420 [==============================] - 1s 61us/step - loss: 0.3217 - accuracy: 0.8479\nEpoch 4/100\n24420/24420 [==============================] - 1s 60us/step - loss: 0.3180 - accuracy: 0.8519\nEpoch 5/100\n24420/24420 [==============================] - 1s 59us/step - loss: 0.3159 - accuracy: 0.8531\nEpoch 6/100\n24420/24420 [==============================] - 1s 61us/step - loss: 0.3141 - accuracy: 0.8525\nEpoch 7/100\n24420/24420 [==============================] - 2s 65us/step - loss: 0.3120 - accuracy: 0.8544\nEpoch 8/100\n24420/24420 [==============================] - 2s 65us/step - loss: 0.3100 - accuracy: 0.8550\nEpoch 9/100\n24420/24420 [==============================] - 2s 65us/step - loss: 0.3081 - accuracy: 0.8557\nEpoch 10/100\n24420/24420 [==============================] - 2s 66us/step - loss: 0.3063 - accuracy: 0.8539\nEpoch 11/100\n24420/24420 [==============================] - 2s 66us/step - loss: 0.3053 - accuracy: 0.8560\nEpoch 12/100\n24420/24420 [==============================] - 2s 64us/step - loss: 0.3033 - accuracy: 0.8584\nEpoch 13/100\n24420/24420 [==============================] - 2s 65us/step - loss: 0.3013 - accuracy: 0.8588\nEpoch 14/100\n24420/24420 [==============================] - 1s 60us/step - loss: 0.3004 - accuracy: 0.8597\nEpoch 15/100\n24420/24420 [==============================] - 1s 60us/step - loss: 0.2992 - accuracy: 0.8590\nEpoch 16/100\n24420/24420 [==============================] - 2s 62us/step - loss: 0.2974 - accuracy: 0.8609\nEpoch 17/100\n24420/24420 [==============================] - 2s 63us/step - loss: 0.2966 - accuracy: 0.8607\nEpoch 18/100\n24420/24420 [==============================] - 2s 62us/step - loss: 0.2950 - accuracy: 0.8619\nEpoch 19/100\n24420/24420 [==============================] - 1s 60us/step - loss: 0.2933 - accuracy: 0.8643\nEpoch 20/100\n24420/24420 [==============================] - 1s 60us/step - loss: 0.2923 - accuracy: 0.8629\nEpoch 21/100\n24420/24420 [==============================] - 1s 60us/step - loss: 0.2914 - accuracy: 0.8625\nEpoch 22/100\n24420/24420 [==============================] - 1s 59us/step - loss: 0.2899 - accuracy: 0.8633\nEpoch 23/100\n24420/24420 [==============================] - 1s 60us/step - loss: 0.2882 - accuracy: 0.8649\nEpoch 24/100\n24420/24420 [==============================] - 2s 64us/step - loss: 0.2871 - accuracy: 0.8670\nEpoch 25/100\n24420/24420 [==============================] - 2s 63us/step - loss: 0.2874 - accuracy: 0.8666\nEpoch 26/100\n24420/24420 [==============================] - 1s 59us/step - loss: 0.2858 - accuracy: 0.8669\nEpoch 27/100\n24420/24420 [==============================] - 1s 59us/step - loss: 0.2841 - accuracy: 0.8670\nEpoch 28/100\n24420/24420 [==============================] - 1s 60us/step - loss: 0.2835 - accuracy: 0.8671\nEpoch 29/100\n24420/24420 [==============================] - 1s 60us/step - loss: 0.2816 - accuracy: 0.8697\nEpoch 30/100\n24420/24420 [==============================] - 1s 60us/step - loss: 0.2808 - accuracy: 0.8689\nEpoch 31/100\n24420/24420 [==============================] - 1s 60us/step - loss: 0.2799 - accuracy: 0.8696\nEpoch 32/100\n24420/24420 [==============================] - 1s 60us/step - loss: 0.2782 - accuracy: 0.8707\nEpoch 33/100\n24420/24420 [==============================] - 1s 60us/step - loss: 0.2781 - accuracy: 0.8700\nEpoch 34/100\n24420/24420 [==============================] - 2s 63us/step - loss: 0.2759 - accuracy: 0.8708\nEpoch 35/100\n24420/24420 [==============================] - 2s 64us/step - loss: 0.2750 - accuracy: 0.8715\nEpoch 36/100\n24420/24420 [==============================] - 1s 60us/step - loss: 0.2737 - accuracy: 0.8739\nEpoch 37/100\n24420/24420 [==============================] - 1s 59us/step - loss: 0.2726 - accuracy: 0.8715\nEpoch 38/100\n24420/24420 [==============================] - 1s 58us/step - loss: 0.2722 - accuracy: 0.8730\nEpoch 39/100\n24420/24420 [==============================] - 1s 59us/step - loss: 0.2712 - accuracy: 0.8729\nEpoch 40/100\n24420/24420 [==============================] - 2s 67us/step - loss: 0.2693 - accuracy: 0.8746\nEpoch 41/100\n23860/24420 [============================>.] - ETA: 0s - loss: 0.2691 - accuracy: 0.8724420/24420 [==============================] - 1s 59us/step - loss: 0.2690 - accuracy: 0.8733\nEpoch 42/100\n24420/24420 [==============================] - 1s 59us/step - loss: 0.2679 - accuracy: 0.8767\nEpoch 43/100\n24420/24420 [==============================] - 1s 61us/step - loss: 0.2663 - accuracy: 0.8772\nEpoch 44/100\n24420/24420 [==============================] - 1s 60us/step - loss: 0.2656 - accuracy: 0.8771\nEpoch 45/100\n24420/24420 [==============================] - 2s 64us/step - loss: 0.2641 - accuracy: 0.8764\nEpoch 46/100\n24420/24420 [==============================] - 1s 61us/step - loss: 0.2637 - accuracy: 0.8767\nEpoch 47/100\n24420/24420 [==============================] - 1s 59us/step - loss: 0.2632 - accuracy: 0.8777\nEpoch 48/100\n24420/24420 [==============================] - 1s 60us/step - loss: 0.2619 - accuracy: 0.8773\nEpoch 49/100\n24420/24420 [==============================] - 1s 59us/step - loss: 0.2617 - accuracy: 0.8779\nEpoch 50/100\n24420/24420 [==============================] - 1s 59us/step - loss: 0.2602 - accuracy: 0.8785\nEpoch 51/100\n24420/24420 [==============================] - 1s 59us/step - loss: 0.2591 - accuracy: 0.8778\nEpoch 52/100\n24420/24420 [==============================] - 1s 59us/step - loss: 0.2583 - accuracy: 0.8803\nEpoch 53/100\n24420/24420 [==============================] - 1s 59us/step - loss: 0.2575 - accuracy: 0.8799\nEpoch 54/100\n24420/24420 [==============================] - 1s 59us/step - loss: 0.2572 - accuracy: 0.8812\nEpoch 55/100\n24420/24420 [==============================] - 1s 59us/step - loss: 0.2565 - accuracy: 0.8798\nEpoch 56/100\n24420/24420 [==============================] - 1s 59us/step - loss: 0.2559 - accuracy: 0.8817\nEpoch 57/100\n24420/24420 [==============================] - 1s 59us/step - loss: 0.2546 - accuracy: 0.8819\nEpoch 58/100\n24420/24420 [==============================] - 1s 59us/step - loss: 0.2545 - accuracy: 0.8817\nEpoch 59/100\n24420/24420 [==============================] - 1s 59us/step - loss: 0.2544 - accuracy: 0.8812\nEpoch 60/100\n24420/24420 [==============================] - 1s 59us/step - loss: 0.2530 - accuracy: 0.8828\nEpoch 61/100\n24420/24420 [==============================] - 1s 59us/step - loss: 0.2518 - accuracy: 0.8817\nEpoch 62/100\n24420/24420 [==============================] - 2s 64us/step - loss: 0.2519 - accuracy: 0.8817\nEpoch 63/100\n24420/24420 [==============================] - 2s 62us/step - loss: 0.2513 - accuracy: 0.8827\nEpoch 64/100\n24420/24420 [==============================] - 1s 61us/step - loss: 0.2498 - accuracy: 0.8835\nEpoch 65/100\n24420/24420 [==============================] - 1s 61us/step - loss: 0.2497 - accuracy: 0.8815\nEpoch 66/100\n24420/24420 [==============================] - 2s 61us/step - loss: 0.2495 - accuracy: 0.8832\nEpoch 67/100\n24420/24420 [==============================] - 2s 63us/step - loss: 0.2494 - accuracy: 0.8828\nEpoch 68/100\n24420/24420 [==============================] - 2s 66us/step - loss: 0.2482 - accuracy: 0.8850\nEpoch 69/100\n24420/24420 [==============================] - 2s 62us/step - loss: 0.2462 - accuracy: 0.8842\nEpoch 70/100\n24420/24420 [==============================] - 2s 62us/step - loss: 0.2456 - accuracy: 0.8856\nEpoch 71/100\n24420/24420 [==============================] - 1s 60us/step - loss: 0.2458 - accuracy: 0.8850\nEpoch 72/100\n24420/24420 [==============================] - 2s 63us/step - loss: 0.2460 - accuracy: 0.8859\nEpoch 73/100\n24420/24420 [==============================] - 2s 63us/step - loss: 0.2445 - accuracy: 0.8867\nEpoch 74/100\n24420/24420 [==============================] - 2s 64us/step - loss: 0.2445 - accuracy: 0.8869\nEpoch 75/100\n24420/24420 [==============================] - 2s 63us/step - loss: 0.2442 - accuracy: 0.8863\nEpoch 76/100\n24420/24420 [==============================] - 1s 61us/step - loss: 0.2431 - accuracy: 0.8892\nEpoch 77/100\n24420/24420 [==============================] - 2s 62us/step - loss: 0.2429 - accuracy: 0.8855\nEpoch 78/100\n24420/24420 [==============================] - 1s 61us/step - loss: 0.2420 - accuracy: 0.8871\nEpoch 79/100\n24420/24420 [==============================] - 2s 63us/step - loss: 0.2425 - accuracy: 0.8872\nEpoch 80/100\n24420/24420 [==============================] - 2s 63us/step - loss: 0.2413 - accuracy: 0.8876\nEpoch 81/100\n24420/24420 [==============================] - 2s 62us/step - loss: 0.2400 - accuracy: 0.8873\nEpoch 82/100\n24420/24420 [==============================] - 1s 61us/step - loss: 0.2416 - accuracy: 0.8863\nEpoch 83/100\n24420/24420 [==============================] - 1s 59us/step - loss: 0.2389 - accuracy: 0.8882\nEpoch 84/100\n24420/24420 [==============================] - 1s 59us/step - loss: 0.2386 - accuracy: 0.8883\nEpoch 85/100\n24420/24420 [==============================] - 1s 59us/step - loss: 0.2397 - accuracy: 0.8878\nEpoch 86/100\n24420/24420 [==============================] - 1s 59us/step - loss: 0.2376 - accuracy: 0.8874\nEpoch 87/100\n24420/24420 [==============================] - 1s 59us/step - loss: 0.2371 - accuracy: 0.8881\nEpoch 88/100\n24420/24420 [==============================] - 1s 59us/step - loss: 0.2367 - accuracy: 0.8885\nEpoch 89/100\n24420/24420 [==============================] - 1s 59us/step - loss: 0.2386 - accuracy: 0.8889\nEpoch 90/100\n24420/24420 [==============================] - 1s 59us/step - loss: 0.2357 - accuracy: 0.8910\nEpoch 91/100\n24420/24420 [==============================] - 1s 59us/step - loss: 0.2359 - accuracy: 0.8905\nEpoch 92/100\n24420/24420 [==============================] - 1s 59us/step - loss: 0.2347 - accuracy: 0.8898\nEpoch 93/100\n24420/24420 [==============================] - 1s 59us/step - loss: 0.2354 - accuracy: 0.8889\nEpoch 94/100\n24420/24420 [==============================] - 1s 59us/step - loss: 0.2346 - accuracy: 0.8910\nEpoch 95/100\n24420/24420 [==============================] - 1s 59us/step - loss: 0.2340 - accuracy: 0.8897\nEpoch 96/100\n24420/24420 [==============================] - 1s 59us/step - loss: 0.2325 - accuracy: 0.8914\nEpoch 97/100\n24420/24420 [==============================] - 1s 60us/step - loss: 0.2320 - accuracy: 0.8900\nEpoch 98/100\n24420/24420 [==============================] - 1s 60us/step - loss: 0.2330 - accuracy: 0.8899\nEpoch 99/100\n24420/24420 [==============================] - 2s 64us/step - loss: 0.2317 - accuracy: 0.8914\nEpoch 100/100\n24420/24420 [==============================] - 2s 64us/step - loss: 0.2322 - accuracy: 0.8912\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<keras.callbacks.callbacks.History at 0x18c925edd88>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "### Batch_size faz com que atualize os pesos a cada 10 dados e treina por 100 √©pocas\n",
    "classificador.fit(previsores_treinamento, classe_treinamento, batch_size=10, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes = classificador.predict(previsores_teste)\n",
    "### Fazendo com que o retorno seja verdadeiro ou falso, baseado num valor m√©dio de 0,5\n",
    "previsoes = (previsoes > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Precis√£o:  0.8301191499815748\n[[5487  672]\n [ 711 1271]]\n"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "precisao = accuracy_score(classe_teste, previsoes)\n",
    "matriz = confusion_matrix(classe_teste, previsoes)\n",
    "print('Precis√£o: ', precisao)\n",
    "print(matriz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos perceber que o algoritmo se saiu melhor sem o OneHotEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}